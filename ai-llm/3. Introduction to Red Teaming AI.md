# Research Papers

* https://arxiv.org/pdf/1707.08945
* https://arxiv.org/pdf/2307.08278
* https://arxiv.org/pdf/2408.13221
* https://arxiv.org/pdf/2311.13647
* https://arxiv.org/pdf/2402.07841
* https://arxiv.org/pdf/2305.13584
* https://arxiv.org/pdf/2405.20975
# ML OWASP Top 10
https://owasp.org/www-project-machine-learning-security-top-10/

|ID|Description|
|---|---|
|ML01|`Input Manipulation Attack`: Attackers modify input data to cause incorrect or malicious model outputs.|
|ML02|`Data Poisoning Attack`: Attackers inject malicious or misleading data into training data, compromising model performance or creating backdoors.|
|ML03|`Model Inversion Attack`: Attackers train a separate model to reconstruct inputs from model outputs, potentially revealing sensitive information.|
|ML04|`Membership Inference Attack`: Attackers analyze model behavior to determine whether data was included in the model's training data set, potentially revealing sensitive information.|
|ML05|`Model Theft`: Attackers train a separate model from interactions with the original model, thereby stealing intellectual property.|
|ML06|`AI Supply Chain Attacks`: Attackers exploit vulnerabilities in any part of the ML supply chain.|
|ML07|`Transfer Learning Attack`: Attackers manipulate the baseline model that is subsequently fine-tuned by a third-party. This can lead to biased or backdoored models.|
|ML08|`Model Skewing`: Attackers skew the model's behavior for malicious purposes, for instance, by manipulating the training data set.|
|ML09|`Output Integrity Attack`: Attackers manipulate a model's output before processing, making it look like the model produced a different output.|
|ML10|`Model Poisoning`: Attackers manipulate the model's weights, compromising model performance or creating backdoors.|
## ML01 - Input Manipulation
* **Rephrasing**: Altering our choice of language, words, phrases, etc. so as to alter how our inputs are classified
* **Overpowering**: Packing with enough benign (i.e. "good") input so as to satisfy classification.
# LLM OWASP Top 10
https://academy.hackthebox.com/module/294/section/3343

|ID|Description|
|---|---|
|LLM01|`Prompt Injection`: Attackers manipulate the LLM's input directly or indirectly to cause malicious or illegal behavior.|
|LLM02|`Insecure Output Handling`: LLM Output is handled insecurely, resulting in injection vulnerabilities such as Cross-Site Scripting (XSS), SQL Injection, or Command Injection.|
|LLM03|`Training Data Poisoning`: Attackers inject malicious or misleading data into the LLM's training data, compromising performance or creating backdoors.|
|LLM04|`Model Denial of Service`: Attackers feed inputs to the LLM that result in high resource consumption, potentially causing disruptions to the LLM service.|
|LLM05|`Supply Chain Vulnerabilities`: Attackers exploit vulnerabilities in any part of the LLM supply chain.|
|LLM06|`Sensitive Information Disclosure`: Attackers trick the LLM into revealing sensitive information in the response.|
|LLM07|`Insecure Plugin Design`: Attackers exploit security vulnerabilities in LLM plugins.|
|LLM08|`Excessive Agency`: Attackers exploit insufficiently restricted LLM access.|
|LLM09|`Overreliance`: An organization is overly reliant on an LLM's output for critical business decisions, potentially leading to security issues from unexpected LLM behavior.|
|LLM10|`Model Theft`: Attackers gain unauthorized access to the LLM itself, stealing intellectual property and potentially causing financial harm.|
